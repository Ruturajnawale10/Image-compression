1. Come up with efficient data structures to represent both types of images: those generated
by the microscope, and those generated by the dye sensor. These need not have the same
representation; the only requirement is that they be compact and take as little storage
space as possible. Explain why you picked the representation you did for each image type,
and if possible estimate how much storage would be taken by the images. What is the
worst-case storage size in bytes for each image representation you chose?
- I've utilized QuadTree as the underlying data structure for representing both image types. Quadtree, primarily employed for image representation and spatial indexing, offers several advantages:

Efficient Compression: QuadTrees excel at compressing images with significant areas of uniform color or intensity. By segmenting the image into smaller sub-regions and storing information solely about non-uniform areas, QuadTrees can compress images using less memory compared to a full grid representation.

Rapid Spatial Queries: QuadTrees facilitate swift spatial queries, such as pinpointing points within a specific region or identifying the nearest neighbor. Leveraging their hierarchical nature, QuadTrees swiftly eliminate irrelevant image portions, hastening search operations.

Adaptive Resolution: QuadTrees permit adaptive resolution representation of images, enabling different sections of the image to possess varying levels of detail. This feature proves valuable when certain image regions demand higher precision or when handling large datasets that cannot be fully loaded into memory.

Simplification and Filtering: QuadTrees find application in image simplification or filtering by consolidating similar regions or eliminating small, isolated segments.

Before compression, the image sizes were 1000x1000x3, totaling 3,000,000 bytes or 3 MB. Post-compression, the size reduction is drastic. For example, the microscope image shrinks to approximately 10~ KB, while the dye image reduces to around 200~ KB. The dye image tends to be larger due to the dispersed behavior of dye molecules.

The worst-case storage size in bytes for each image representation is initially calculated as 1000x1000x3, amounting to 3,000,000 bytes or 3 MB for both the microscope and dye images. However, this scenario is highly improbable since the microscope image typically consists of contiguous black pixels for the parasite, and the dye is predominantly spread near the parasite. Thus, the worst-case storage size in bytes for each image representation is approximately O(Image Size^2).

2. Before the researchers give you real images to work with, you would like to test out any
code you write. To this end, you would like to create “fake” simulated images and pretend
they were captured by the microscope and the dye sensor. Using the data structures you
chose in (1) above, write code to create such simulated images. Try and be as realistic in the
generated images as possible.
- I'm creating synthetic microscope and dye images using the 'simulate_images.py' script. Additionally, I'm ensuring that only 0.1% of parasites will exhibit cancer (for further details, please check the code).

3. Using the simulated images generated by the code you wrote for (2) above as input, write a
function to compute whether a parasite has cancer or not.
- main.py is the entrypoint of the code. I used two algorithms to compute whether parasite has cancer or not. One using quad trees for traversal which is the faster version than the other naive version.

4. You give your code from (3) to the researchers, who run it and find that it is running too
slowly for their liking. What can you do to improve the execution speed? Write the code to
implement the fastest possible version you can think of for the function in (3).
- 
I've developed three distinct algorithms to determine whether parasites have cancer:

Naive slow Method: Employing a brute-force approach, I've utilized nested for loops to meticulously check for overlap between the images. However, due to its exhaustive nature, this method is considerably slow.

Fast Method using Quad Trees: Utilizing a quadtree representation to store the images, I've adopted a divide and conquer strategy. By dividing the images into four parts and comparing them, I efficiently identify overlaps. If the images match, I aggregate the area to the total overlap; otherwise, I recursively divide and compare. This method proves to be significantly faster.

Fastest Method using cached black pixels: Enhancing the efficiency further, I've cached the number of black pixels in the microscope image during extraction from the compressed format. Leveraging this cache, I compute the overlap between the images. This method outperforms the fast method in terms of speed.

Additional Proposed Improvement: I also propose that we can use parallel processing in divide and conquer to improve speed of execution but the problem would be with the number of available threads and cores in the CPU especially since the number of nodes in the quad trees are a lot.

In the code, I've implemented the slow and faster methods, as the faster method is essentially an enhancement of the fast method.

Through trial runs, I've observed that the faster method is approximately 2-3 times quicker than the slow method. I've provided the results and execution times in the terminal for your reference. Feel free to test it out following the instructions outlined in the README file.

5. What other compression techniques can you suggest for both types of images (parasite and
dye)? How would they impact runtime? Can you compute actual runtime and storage costs
for typical images (not oversimplified image such as a circle for the parasite, or simple
straight lines or random points for dye) in your code? The measurements should be done on
your computer with an actual image size of 100,000x100,000 pixels (and not a scaled down
version).
- Run-Length Encoding (RLE): Considering the dispersed behavior of dye molecules, Run-Length Encoding (RLE) can be an efficient compression technique for dye sensor images. RLE represents consecutive data values as single data values and their counts. Since dye images often exhibit contiguous areas of the same color, RLE can effectively compress such regions, resulting in compact storage.
Estimated Storage: While the exact storage reduction would depend on the specific characteristics of the image, RLE can significantly reduce storage compared to uncompressed formats, such as the original 1000x1000x3 size.

6. Describes what tools you used to solve the challenge, particularly any LLM techniques.
- I used Github copilot which auto suggested some of the additional code snippets for me based on my code. Besides, I used chatgpt to get ideas, stack overflow to resolve queries.
